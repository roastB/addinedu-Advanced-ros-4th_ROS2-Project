import streamlit as st
import warnings
from typing import Annotated, List
from typing_extensions import TypedDict
from dotenv import load_dotenv

from langchain_core.messages import AIMessage, BaseMessage, HumanMessage
from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder
from langchain_core.output_parsers import StrOutputParser
from langchain_core.runnables import RunnableConfig
from langchain_openai import ChatOpenAI
from langchain_teddynote import logging
from langchain_teddynote.graphs import visualize_graph
from langchain_teddynote.messages import random_uuid, stream_graph
from langchain_teddynote.models import LLMs, get_model_name
from langgraph.graph import END, StateGraph
from langgraph.graph.message import add_messages

# ì´ˆê¸° ì„¤ì •
load_dotenv()
warnings.filterwarnings("ignore")
logging.langsmith("test.ipynb")

MODEL_NAME = "gpt-4o"

# State ì •ì˜
class State(TypedDict):
    messages: Annotated[list, add_messages]

# ìƒë‹´ì‚¬ ì±—ë´‡ í˜¸ì¶œ í•¨ìˆ˜
def call_chatbot(messages: List[BaseMessage]) -> dict:
    prompt = ChatPromptTemplate.from_messages([
        ("system", "You're a system that takes orders from Servoway, Answer in Korean"),
        MessagesPlaceholder(variable_name="messages")
    ])
    model = ChatOpenAI(model=MODEL_NAME, temperature=0.6)
    chain = prompt | model | StrOutputParser()
    return chain.invoke({"messages": messages})

# ê³ ê° ì‹œë‚˜ë¦¬ì˜¤ ìƒì„± í•¨ìˆ˜
def create_scenario(name: str, instructions: str):
    system_prompt_template = """ ë‹¹ì‹ ì€ ì„œë³´ì›¨ì´ì˜ ê³ ê°ì…ë‹ˆë‹¤.\në‹¨ì¼ ìƒŒë“œìœ„ì¹˜ë¥¼ ì£¼ë¬¸í•  ìˆ˜ ìˆê³ , í–„, ì¹˜ì¦ˆ, ì–‘ìƒì¶”ë¥¼ 3ê°œ ì œí•œìœ¼ë¡œ ì¶”ê°€í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n\n[ì¤‘ìš”]\n- ì£¼ë¬¸ê³¼ ê´€ë ¨ëœ ëŒ€ë‹µë§Œ í•´ì•¼ í•©ë‹ˆë‹¤.\n- í•œêµ­ì–´ë¡œ ëŒ€í™”ë¥¼ í•´ì•¼ í•©ë‹ˆë‹¤."""
    prompt = ChatPromptTemplate.from_messages([
        ("system", system_prompt_template),
        MessagesPlaceholder(variable_name="message")
    ])
    return prompt.partial(name=name, instructions=instructions)

# ì—­í•  ìŠ¤ì™‘ í•¨ìˆ˜
def _swap_roles(messages):
    new_messages = []
    for m in messages:
        if isinstance(m, AIMessage):
            new_messages.append(HumanMessage(content=m.content))
        else:
            new_messages.append(AIMessage(content=m.content))
    return new_messages

# Streamlit UI ì‹œì‘
st.set_page_config(page_title="AI ìƒë‹´ì‚¬ ì‹œë®¬ë ˆì´ì…˜", page_icon="ğŸ’¬")
st.title("ğŸ’¬ AI ìƒë‹´ì‚¬-ê³ ê° ëŒ€í™” ì‹œë®¬ë ˆì´ì…˜")

user_input = st.text_input("ğŸ‘¤ ì‚¬ìš©ì ì²« ì…ë ¥:", "ì•ˆë…•í•˜ì„¸ìš” ìƒŒë“œìœ„ì¹˜ ì£¼ë¬¸í•˜ë ¤ê³  í•©ë‹ˆë‹¤")

if st.button("â–¶ï¸ ì‹œë®¬ë ˆì´ì…˜ ì‹œì‘"):
    with st.spinner("ì‹œë®¬ë ˆì´ì…˜ ì‹¤í–‰ ì¤‘..."):
        instructions = "ë‹¨ì¼ ìƒŒë“œìœ„ì¹˜ë¥¼ ì£¼ë¬¸í•˜ê³  ì‹¶ìŠµë‹ˆë‹¤."
        name = "customer"

        simulated_user = create_scenario(name, instructions) | ChatOpenAI(model=MODEL_NAME, temperature=0.1) | StrOutputParser()

        def ai_assistant_node(state: State):
            ai_response = call_chatbot(state["messages"])
            return {"messages": [("assistant", ai_response)]}

        def simulated_user_node(state: State):
            new_messages = _swap_roles(state["messages"])
            response = simulated_user.invoke({"messages": new_messages})
            return {"messages": [("user", response)]}

        def should_continue(state: State):
            if len(state["messages"]) > 6 or state["messages"][-1].content == "FINISHED":
                return "end"
            else:
                return "continue"

        graph_builder = StateGraph(State)
        graph_builder.add_node("simulated_user", simulated_user_node)
        graph_builder.add_node("ai_assistant", ai_assistant_node)
        graph_builder.add_conditional_edges(
            "simulated_user",
            should_continue,
            {
                "end": END,
                "continue": "ai_assistant",
            },
        )
        graph_builder.set_entry_point("ai_assistant")
        simulation = graph_builder.compile()

        config = RunnableConfig(recursion_limit=10, configurable={"thread_id": random_uuid()})
        inputs = {"messages": [HumanMessage(content=user_input)]}

        st.success("ğŸ‘ ì‹œë®¬ë ˆì´ì…˜ ì™„ë£Œ! ëŒ€í™” ë¡œê·¸ë¥¼ ì•„ë˜ì—ì„œ í™•ì¸í•˜ì„¸ìš”.")
        stream_graph(simulation, inputs, config, node_names=["simulated_user", "ai_assistant"])
