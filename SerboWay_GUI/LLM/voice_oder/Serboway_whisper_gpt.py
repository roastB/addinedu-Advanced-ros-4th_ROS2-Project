import os
import json
import io
import streamlit as st
import whisper
import sounddevice as sd
import soundfile as sf
import openai
from gtts import gTTS

from langgraph.graph import StateGraph, END
from langchain_core.messages import AIMessage, HumanMessage
from typing import TypedDict, List, Annotated, Union
from langgraph.graph.message import add_messages

# â”€â”€â”€ Configuration â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

openai.api_key = os.getenv("OPENAI_API_KEY")

st.set_page_config(page_title="ì„œë³´ì›¨ì´ AI ì£¼ë¬¸", page_icon="ğŸ¥ª")
st.title("ğŸ¥ª ì„œë³´ì›¨ì´ AI ì£¼ë¬¸ ì‹œìŠ¤í…œ")

# â”€â”€â”€ State Type â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

class OrderState(TypedDict):
    messages: Annotated[List[Union[AIMessage, HumanMessage]], add_messages]
    order: dict

# â”€â”€â”€ Whisper STT â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

def speech_to_text() -> str:
    """5ì´ˆ Whisper ë…¹ìŒ í›„ í•œêµ­ì–´ë¡œ í…ìŠ¤íŠ¸ ë°˜í™˜"""
    st.info("ë§ì”€í•´ì£¼ì„¸ìš”...", icon="ğŸ¤")
    sd.default.samplerate = 16000
    sd.default.channels = 1
    recording = sd.rec(int(5 * 16000))
    sd.wait()
    wav_path = "temp_whisper.wav"
    sf.write(wav_path, recording, 16000)

    model = whisper.load_model("base")
    result = model.transcribe(wav_path, language="ko")
    return result["text"]

# â”€â”€â”€ GPT Parsing & Guidance â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

def gpt_parse_and_respond(last_text: str, history: List[dict]) -> tuple[dict, str]:
    """
    GPT function_callì„ ì´ìš©í•´
      - menu: ê³ ì • 'ì„œë³´ìœ„ì¹˜'
      - ingredients: ['í–„','ì¹˜ì¦ˆ','ì–‘ìƒì¶”'] ì¤‘ ìµœì†Œ 1ê°œ ìµœëŒ€ 3ê°œ
      - confirmed: bool
    ì„ íŒŒì‹±í•˜ê³ ,
    GPTê°€ ì‚¬ìš©ìì—ê²Œ í•  ì•ˆë‚´ ë¬¸êµ¬ë„ í•¨ê»˜ ë°˜í™˜í•©ë‹ˆë‹¤.
    """
    functions = [{
        "name": "parse_order",
        "description": "ì‚¬ìš©ì ë°œí™”ì—ì„œ ê³ ì • ë©”ë‰´ì™€ ì¬ë£Œ/ì™„ë£Œì—¬ë¶€ë¥¼ íŒŒì‹±í•©ë‹ˆë‹¤.",
        "parameters": {
            "type": "object",
            "properties": {
                "menu": {
                    "type": "string",
                    "enum": ["ì„œë³´ìœ„ì¹˜"]
                },
                "ingredients": {
                    "type": "array",
                    "items": {
                        "type": "string",
                        "enum": ["í–„", "ì¹˜ì¦ˆ", "ì–‘ìƒì¶”"]
                    },
                    "maxItems": 3
                },
                "confirmed": {
                    "type": "boolean"
                }
            },
            "required": ["menu", "ingredients", "confirmed"]
        }
    }]

    resp = openai.Chat.Completion.create(
        model="gpt-4o",
        messages=history + [{"role": "user", "content": last_text}],
        functions=functions,
        function_call={"name": "parse_order"}
    )

    msg = resp.choices[0].message
    args = json.loads(msg.function_call.arguments)
    reply = msg.content or ""

    return args, reply

# â”€â”€â”€ StateGraph Nodes â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

def process_order_node(state: OrderState):
    last = state["messages"][-1].content
    history = [
        {"role": "assistant", "content": m.content} if isinstance(m, AIMessage)
        else {"role": "user", "content": m.content}
        for m in state["messages"]
    ]
    order, reply = gpt_parse_and_respond(last, history)
    state["order"] = order

    if not reply:
        ing = order["ingredients"]
        if not ing:
            reply = "ì¬ë£Œë¥¼ í•œ ê°€ì§€ ì´ìƒ ì„ íƒí•´ì£¼ì„¸ìš”."
        elif not order["confirmed"]:
            sel = ", ".join(ing)
            reply = f"{sel} ì¬ë£Œë¡œ ì£¼ë¬¸ì„ í™•ì •í•˜ì‹œê² ìŠµë‹ˆê¹Œ? (ë„¤/ì•„ë‹ˆì˜¤)"
        else:
            reply = "âœ… ì£¼ë¬¸ ì™„ë£Œ! ë§¤ì¥ì—ì„œ ë°”ë¡œ ì¤€ë¹„í•©ë‹ˆë‹¤."

    return {"messages": [AIMessage(reply)], "order": order}

def confirm_order_node(state: OrderState):
    last = state["messages"][-1].content.lower()
    if "ë„¤" in last:
        state["order"]["confirmed"] = True
        return {
            "messages": [AIMessage("âœ… ì£¼ë¬¸ ì™„ë£Œ! ë§¤ì¥ì—ì„œ ë°”ë¡œ ì¤€ë¹„í•©ë‹ˆë‹¤.")],
            "order": state["order"]
        }
    else:
        return {
            "messages": [AIMessage("ğŸ”„ ì£¼ë¬¸ì„ ë‹¤ì‹œ ì‹œì‘í•´ì£¼ì„¸ìš”.")],
            "order": {}
        }

def route_message(state: OrderState):
    if state["order"].get("confirmed"):
        return END
    last = state["messages"][-1].content.lower()
    if any(kw in last for kw in ["ë„¤", "ì•„ë‹ˆì˜¤"]):
        return "confirm"
    return "process"

# â”€â”€â”€ Streamlit UI & Workflow â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

# ì´ˆê¸° í™˜ì˜ ë©”ì‹œì§€
if "messages" not in st.session_state:
    st.session_state.messages = [AIMessage("ì–´ì„œì˜¤ì„¸ìš”! ì–´ë–¤ ë©”ë‰´ë¥¼ ì£¼ë¬¸í•˜ì‹œê² ì–´ìš”?")]

# ëŒ€í™” ê¸°ë¡ ì¶œë ¥
for msg in st.session_state.messages:
    role = "user" if isinstance(msg, HumanMessage) else "assistant"
    st.chat_message(role).write(msg.content)

# ì‚¬ìš©ì ì…ë ¥: í…ìŠ¤íŠ¸ + ìŒì„±
input_col, voice_col = st.columns([5, 1])
with input_col:
    text_input = st.chat_input("ì£¼ë¬¸ì„ ì…ë ¥í•˜ì„¸ìš”â€¦")
with voice_col:
    if st.button("ğŸ¤", use_container_width=True):
        text_input = speech_to_text()

if text_input:
    # ì‚¬ìš©ì ë©”ì‹œì§€ ì„¸ì…˜ì— ì €ì¥
    st.session_state.messages.append(HumanMessage(text_input))
    st.chat_message("user").write(text_input)

    # StateGraph ì„¸íŒ…
    wf = StateGraph(OrderState)
    wf.add_node("process", process_order_node)
    wf.add_node("confirm", confirm_order_node)
    wf.add_conditional_edges("process", route_message, {
        "confirm": "confirm",
        "process": END
    })
    wf.add_edge("confirm", END)
    wf.set_entry_point("process")

    # â”€â”€â”€ ì—¬ê¸°ì„œ compile() í›„ invoke() í•´ì•¼ í•©ë‹ˆë‹¤ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    compiled_wf = wf.compile()
    result = compiled_wf.invoke({
        "messages": st.session_state.messages,
        "order": {}
    })

    # AI ì‘ë‹µ í‘œì‹œ
    ai_res = result["messages"][-1]
    st.session_state.messages.append(ai_res)
    st.chat_message("assistant").write(ai_res.content)

    # TTS: gTTSë¡œ ìŒì„± ì¬ìƒ
    tts = gTTS(ai_res.content, lang="ko")
    buf = io.BytesIO()
    tts.write_to_fp(buf)
    buf.seek(0)
    st.audio(buf.read(), format="audio/mp3")

    # 'ë‹¤ì‹œ ì£¼ë¬¸' í‚¤ì›Œë“œë¡œ ì´ˆê¸°í™”
    if "ë‹¤ì‹œ ì£¼ë¬¸" in ai_res.content:
        st.session_state.messages = [
            AIMessage("ìƒˆ ì£¼ë¬¸ì„ ì‹œì‘í•©ë‹ˆë‹¤. ë©”ë‰´ë¥¼ ì„ íƒí•´ì£¼ì„¸ìš”.")
        ]
        st.rerun()
